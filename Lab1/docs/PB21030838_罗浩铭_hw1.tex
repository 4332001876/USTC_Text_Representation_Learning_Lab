\documentclass[twoside,11pt]{article}
%\documentclass[UTF8]{ctexart}
\usepackage[heading=true]{ctex}

\usepackage{listings}
\usepackage{color}

\usepackage{multirow}
\usepackage{booktabs}

\definecolor{dkgreen}{rgb}{0,0.6,0}
\definecolor{gray}{rgb}{0.5,0.5,0.5}
\definecolor{mauve}{rgb}{0.58,0,0.82}

\lstset{frame=tb,
  language=Python,
  aboveskip=3mm,
  belowskip=3mm,
  showstringspaces=false,
  columns=flexible,
  basicstyle={\small\ttfamily},
  numbers=none,
  numberstyle=\tiny\color{gray},
  keywordstyle=\color{blue},
  commentstyle=\color{dkgreen},
  stringstyle=\color{mauve},
  breaklines=true,
  breakatwhitespace=true,
  tabsize=3
}

\usepackage{fancyhdr} % 页眉页脚
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage[colorlinks=true, allcolors=blue]{hyperref}
%\usepackage[margin=1.5in]{geometry}

\oddsidemargin .25in    %   Note \oddsidemargin = \evensidemargin
\evensidemargin .25in
\marginparwidth 0.07 true in
%\marginparwidth 0.75 true in
%\topmargin 0 true pt           % Nominal distance from top of page to top of
%\topmargin 0.125in
\topmargin -0.1in
\addtolength{\headsep}{0.25in}
\textheight 8.5 true in       % Height of text (including footnotes & figures)
\textwidth 6.0 true in        % Width of text line.
\widowpenalty=10000
\clubpenalty=10000


\pagestyle{fancy}

%\firstpageno{1}

\title{文本表征学习HW1}

\author{罗浩铭\ PB21030838}


\begin{document}

\fancyhf{} % 清除所有页眉页脚
\fancyfoot[C]{\thepage} % 设置右页脚为页码
\fancyhead[l]{\footnotesize USTC Text Representation Learning} % 设置左页眉为课程名称
% 设置右页眉为章节标题 

\renewcommand{\headrulewidth}{0pt} % 去页眉线

\begin{center}
  \textbf{\LARGE{文本表征学习HW1}}\\
  \vspace{0.1cm}
  \large{罗浩铭\ PB21030838}
\end{center}


% 实验报告要求：使用训练数据构建统计语言模型并使用不同平滑方法优化模型，对比分析不同模型及平滑策略在不同测试集上的性能（perplexity），完成并提交1-2页的实验报告


% ·bigram语言模型与trigram语言模型的比较分析
% ·通过语言模型在不使用平滑、使用加一平滑、使用古德-图灵平滑时在不同数据集上性能的比较，讨论比较不同平滑策略的优劣
% ·上述讨论与分析依据的具体模型参数和性能数值
% ·简要描述实现模型的过程，其中使用了哪些数据结构，遇到了哪些问题，是如何解决的


\section{模型实现}
\subsection{N-gram模型实现}
本次实验数据集中提供的句子均已完成分词，因此我们可以直接根据分词结果来构建N-gram模型。
我们读入每一行句子，并使用nltk.util.ngrams来生成每个句子中含有的n-gram序列（左右各填充"<bos>"与"<eos>"），将其合并为一个列表。
然后使用Python的collections.Counter类来统计每种n-gram出现的次数，作为频率。


\subsection{平滑方法实现}

\section{实验结果}
\subsection{bigram与trigram模型性能对比}
\begin{table}[htbp]
  \renewcommand{\multirowsetup}{\centering}
  \caption{bigram与trigram模型在不同平滑方法下得到的Perplexity中位数}
  \label{tab:hyperparams}
  \vspace{5pt}
  \centering
  \begin{tabular}{cccc}
    \toprule
    \multicolumn{2}{c}{组别} & Bigram模型      & Trigram模型                               \\
    \midrule
    \multirow{3}{*}{测试集1} & 不使用平滑      & inf                 & inf                 \\
                             & 加一平滑        & $8.015 \times 10^3$ & $3.028 \times 10^4$ \\
                             & Good-Turing平滑 & $3.426 \times 10^2$ & $5.448 \times 10^1$ \\
    \midrule
    \multirow{3}{*}{测试集2} & 不使用平滑      & $7.230 \times 10^1$ & inf                 \\
                             & 加一平滑        & $2.056\times 10^3$  & $1.029 \times 10^4$ \\
                             & Good-Turing平滑 & $7.849 \times 10^1$ & $5.752 \times 10^1$ \\
    \bottomrule
  \end{tabular}
\end{table}


\end{document}

